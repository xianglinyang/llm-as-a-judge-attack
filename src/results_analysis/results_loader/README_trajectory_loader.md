# Trajectory Loader

The trajectory loader provides functionality to load, parse, and analyze trajectory files generated by various exploration strategies (UCB, random, simple rewrite, etc.) in the LLM-as-a-Judge attack framework.

## Overview

Trajectory files contain the complete exploration history for each question, including:
- Initial responses and scores
- Step-by-step exploration with different bias strategies
- Final results and improvements
- Metadata about the experimental setup

## File Structure

Trajectory files are saved in JSON format with the following structure:

```json
{
  "strategy": "ucb",
  "judge_type": "pointwise", 
  "dataset_name": "AlpacaEval",
  "judge_backbone": "gpt-4",
  "llm_agent_name": "gpt-4.1-nano",
  "response_model_name": "gpt-4.1-mini",
  "baseline_response_model_name": "gpt-3.5-turbo",
  "budget": 20,
  "pool_size": 3,
  "eval_num": 100,
  "timestamp": "2024-01-15 10:30:00",
  "time_taken": 150.5,
  "alpha": 1.0,
  "lambda_reg": 1.0,
  "reward_type": "relative",
  "trajectories": [
    {
      "question": "What is machine learning?",
      "score": 8.5,
      "answer": "Final improved answer...",
      "explanation": "Judge's explanation",
      "origin": "improved_clarity",
      "tokens": 120,
      "category": "AI",
      "history": [
        [7.0, "Initial explanation", "Initial answer", "init"],
        [8.5, "Improved explanation", "Final answer", "strategy_name"]
      ]
    }
  ]
}
```

## Usage

### Basic Loading

```python
from trajectory_loader import load_trajectory_directory, load_single_trajectory

# Load all trajectories from a directory
trajectories = load_trajectory_directory("/path/to/trajectory/files")

# Load a single file
trajectory = load_single_trajectory("/path/to/file.json")
```

### Filtering and Exclusion

```python
# Filter by strategy (include only) - using filter_criteria
from trajectory_loader import parse_filter_criteria
filter_criteria = parse_filter_criteria("strategy=ucb")
ucb_trajectories = load_trajectory_directory("/path/to/files", filter_criteria=filter_criteria)

# Filter by dataset (include only) - using filter_criteria
filter_criteria = parse_filter_criteria("dataset_name=AlpacaEval")
alpaca_trajectories = load_trajectory_directory("/path/to/files", filter_criteria=filter_criteria)

# Multiple filters (include only) - using filter_criteria
filter_criteria = parse_filter_criteria("strategy=ucb,judge_type=pointwise")
filtered = load_trajectory_directory("/path/to/files", filter_criteria=filter_criteria)

# Legacy filtering (still supported for backward compatibility)
filtered_legacy = load_trajectory_directory("/path/to/files", 
                                          strategy="ucb", 
                                          judge_type="pointwise")

# Exclude by criteria
from trajectory_loader import parse_exclude_criteria

exclude_criteria = parse_exclude_criteria("dataset_name=AlpacaEval,strategy=random")
trajectories = load_trajectory_directory("/path/to/files", 
                                        exclude_criteria=exclude_criteria)

# Combine filtering and exclusion
trajectories = load_trajectory_directory("/path/to/files",
                                        filter_criteria={"strategy": ["ucb"]},  # include only UCB
                                        exclude_criteria={"judge_backbone": ["gpt-3.5"]})  # exclude GPT-3.5
```

### Advanced Usage

```python
from trajectory_loader import TrajectoryLoader

loader = TrajectoryLoader("/path/to/trajectory/files")

# Load with exclusion patterns
trajectories = loader.load_trajectories(exclude_patterns=['warmup', 'init'])

# Group by metadata field
strategy_groups = loader.group_trajectories_by(trajectories, "strategy")

# Filter loaded trajectories
ucb_only = loader.filter_trajectories(trajectories, strategy="ucb")
```

### Analysis

```python
# Access trajectory data
for trajectory in trajectories:
    print(f"Strategy: {trajectory.metadata.strategy}")
    print(f"Dataset: {trajectory.metadata.dataset_name}")
    print(f"Questions: {len(trajectory.trajectories)}")
    
    # Get aggregated metrics
    final_scores = trajectory.get_final_scores()
    improvements = trajectory.get_improvements()
    exploration_lengths = trajectory.get_exploration_lengths()
    
    print(f"Mean improvement: {sum(improvements) / len(improvements):.3f}")
    
    # Analyze individual trajectories
    for item in trajectory.trajectories:
        print(f"Question: {item.question}")
        print(f"Initial score: {item.initial_score}")
        print(f"Final score: {item.final_score}")
        print(f"Improvement: {item.improvement}")
        print(f"Strategies used: {item.strategies_used}")
```

## Data Classes

### TrajectoryMetadata
Contains metadata about the experimental setup:
- `strategy`: Exploration strategy used
- `judge_type`: Type of judge evaluation
- `dataset_name`: Dataset used
- `judge_backbone`: Judge model
- `budget`: Exploration budget
- `pool_size`: Pool size for exploration
- And more...

### TrajectoryStep
Represents a single step in the exploration:
- `score`: Judge score for this step
- `explanation`: Judge's explanation
- `answer`: Response text
- `strategy_or_origin`: Strategy used or "init" for initial

### TrajectoryItem
Represents the complete trajectory for one question:
- `question`: Original question
- `final_score`: Final achieved score
- `final_answer`: Final response
- `history`: List of TrajectoryStep objects
- `category`: Question category
- Properties: `initial_score`, `improvement`, `exploration_length`, `strategies_used`

### LoadedTrajectory
Complete loaded trajectory data:
- `metadata`: TrajectoryMetadata object
- `trajectories`: List of TrajectoryItem objects
- Methods: `get_final_scores()`, `get_improvements()`, `get_categories()`, etc.

## Command Line Usage

### Analyze trajectories
```bash
cd src/results_analysis

# Basic usage (uses default directory)
python trajectory_loader.py --show_summary

# Specify directory
python trajectory_loader.py --directory /path/to/trajectory/files --show_summary

# Filter by strategy
python trajectory_loader.py --filter "strategy=ucb" --show_summary

# Filter by dataset
python trajectory_loader.py --filter "dataset_name=AlpacaEval" --show_summary

# Filter by multiple criteria (AND logic - all must match)
python trajectory_loader.py --filter "strategy=ucb,judge_type=pointwise" --show_summary

# Exclude specific criteria (OR logic - any match means exclude)
python trajectory_loader.py --exclude "dataset_name=AlpacaEval" --show_summary

# Exclude multiple values
python trajectory_loader.py --exclude "dataset_name=AlpacaEval,strategy=random" --show_summary

# Combine filtering and exclusion
python trajectory_loader.py --filter "strategy=ucb" --exclude "judge_backbone=gpt-3.5" --show_summary

# Complex filtering (multiple criteria + exclude)
python trajectory_loader.py --filter "strategy=ucb,judge_type=pointwise" --exclude "dataset_name=AlpacaEval" --show_summary
```

## Filter and Exclusion Syntax

Both `--filter` and `--exclude` arguments support the following format:
```
--filter "key1=value1,key2=value2,key1=value3"
--exclude "key1=value1,key2=value2,key1=value3"
```

### Filter vs Exclude Logic

**Filter (`--filter`):**
- **AND logic across different keys**: ALL criteria must be satisfied
- **OR logic within same key**: ANY value for the same key can match
- Example: `--filter "strategy=ucb,judge_type=pointwise"` 
  - Includes only files where strategy IS ucb AND judge_type IS pointwise

**Exclude (`--exclude`):**
- **OR logic**: ANY criteria match means exclude
- Example: `--exclude "strategy=random,dataset_name=AlpacaEval"`
  - Excludes files where strategy IS random OR dataset_name IS AlpacaEval

### Supported Fields
You can filter or exclude based on any metadata field:
- `strategy` - Exploration strategy (ucb, random, simple_rewrite_holistic, etc.)
- `dataset_name` or `dataset` - Dataset name (AlpacaEval, UltraFeedback, etc.)
- `judge_backbone` or `judge` - Judge model (gpt-4, gpt-3.5-turbo, etc.)
- `judge_type` - Judge type (pointwise, pairwise, etc.)
- `llm_agent_name` - LLM agent model
- `response_model_name` - Response model
- `baseline_response_model_name` - Baseline model
- `budget` - Exploration budget
- `pool_size` - Pool size
- `reward_type` - Reward type (relative, absolute)
- `alpha` - UCB alpha parameter
- `lambda_reg` - Regularization parameter

### Examples
```bash
# Filter: Include only UCB strategy
--filter "strategy=ucb"

# Filter: Include only UCB AND pointwise evaluation
--filter "strategy=ucb,judge_type=pointwise"

# Filter: Include UCB OR random strategies (multiple values for same key)
--filter "strategy=ucb,strategy=random"

# Exclude: Remove AlpacaEval dataset
--exclude "dataset_name=AlpacaEval"

# Exclude: Remove multiple datasets (OR logic)
--exclude "dataset_name=AlpacaEval,dataset_name=UltraFeedback"

# Exclude: Remove random strategy OR GPT-3.5 judge (OR logic)
--exclude "strategy=random,judge_backbone=gpt-3.5"

# Combined: Include only UCB, but exclude GPT-3.5 judge
--filter "strategy=ucb" --exclude "judge_backbone=gpt-3.5"

# Alternative field names work too
--filter "dataset=AlpacaEval,judge=gpt-4"
```

### Matching Behavior
- Matching is case-insensitive
- Supports both exact matches and substring matches
- Multiple values for the same field are OR'd together
- **Filter**: Different fields are AND'd together (include if ALL criteria match)
- **Exclude**: Different fields are OR'd together (exclude if ANY criteria match)

## Default File Exclusions

By default, the loader excludes files with these patterns in their names:
- `warmup`
- `init_ucb`
- `init_linucb`
- `warmup_summary`

These filename-based exclusions can be overridden by providing custom `exclude_patterns`.

## Integration with Existing Code

The trajectory loader is designed to work with existing visualization and analysis scripts. It provides a clean interface to access the trajectory data that was previously loaded manually in various analysis scripts.

For example, the `plot_multi_dimensional_comparison.py` script can be extended to use this loader for more robust data loading and filtering.
