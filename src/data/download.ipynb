{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/mnt/hdd1/ljiahao/xianglin/cache/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"/mnt/hdd1/ljiahao/xianglin/llm-as-a-judge-attack/raw\"\n",
    "data_path = \"/mnt/hdd1/ljiahao/xianglin/llm-as-a-judge-attack/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format\n",
    "1. download data to raw data path, or huggingface default path\n",
    "2. save metadata.json to data_path, including keys: instruction, (category), others\n",
    "3. save completion json to data_path/model_name.json, including keys: instruction, output,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd raw_path\n",
    "!git clone https://huggingface.co/spaces/lmsys/mt-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{raw_path}/mt-bench/data/mt_bench/question.jsonl\"\n",
    "import json\n",
    "\n",
    "# load jsonl\n",
    "questions = []\n",
    "with open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        questions.append(data)\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metadata to data\n",
    "mt_bench_path = os.path.join(data_path, \"MTBench\")\n",
    "os.makedirs(mt_bench_path, exist_ok=True)\n",
    "save_path = os.path.join(mt_bench_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for question in questions:\n",
    "    metadata.append({\n",
    "        \"question_id\": question['question_id'],\n",
    "        \"instruction\": question['turns'][0],\n",
    "        \"original_category\": question['category'],\n",
    "    })\n",
    "\n",
    "# save metadata to data\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model answer\n",
    "answer_dir = os.path.join(raw_path, \"mt-bench/data/mt_bench/model_answer\")\n",
    "files = os.listdir(answer_dir)\n",
    "\n",
    "for file in files:\n",
    "    model_name = file.split(\".\")[0]\n",
    "\n",
    "    # load model answer\n",
    "    path = os.path.join(answer_dir, file)\n",
    "    answers = list()\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            answers.append(data)\n",
    "    \n",
    "    new_dataset = list()\n",
    "    for answer in answers:\n",
    "        for question in questions:\n",
    "            if answer['question_id'] == question['question_id']:\n",
    "                new_item = {\n",
    "                    \"instruction\": question['turns'][0],\n",
    "                    \"output\": answer['choices'][0]['turns'][0],\n",
    "                    \"original_category\": question['category'],\n",
    "                }\n",
    "                new_dataset.append(new_item)\n",
    "    \n",
    "    print(model_name)\n",
    "    print(new_dataset[0])\n",
    "    print(\"-\"*100)\n",
    "    # save new dataset\n",
    "    save_path = os.path.join(mt_bench_path, f\"{model_name}.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(new_dataset, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlpacaEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd raw_path\n",
    "!git clone https://github.com/tatsu-lab/alpaca_eval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(raw_path, \"alpaca_eval\", \"results\", \"NullModel\", \"model_outputs.json\")\n",
    "\n",
    "# load jsonl\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_path = os.path.join(data_path, \"AlpacaEval\")\n",
    "os.makedirs(alpaca_path, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(alpaca_path, \"metadata.json\")\n",
    "metadata = list()\n",
    "for item in data:\n",
    "    metadata.append({\n",
    "        \"instruction\": item[\"instruction\"],\n",
    "        \"dataset\": item[\"dataset\"]\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "# Show example element\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = os.path.join(raw_path, \"alpaca_eval\", \"results\")\n",
    "dirs = os.listdir(result_dir)\n",
    "\n",
    "for dir in dirs:\n",
    "    path = os.path.join(result_dir, dir, \"model_outputs.json\")\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    new_dataset = list()\n",
    "    for item in data:\n",
    "        new_dataset.append({\n",
    "            \"instruction\": item[\"instruction\"],\n",
    "            \"output\": item[\"output\"]\n",
    "        })\n",
    "    print(dir)\n",
    "    print(new_dataset[0])\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    save_path = os.path.join(alpaca_path, f\"{dir}.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(new_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArenaHard 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/lmarena/arena-hard-auto.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "save_dir = os.path.join(raw_path, \"arena-hard-auto\", \"data\", \"arena-hard-v2.0\")\n",
    "\n",
    "questions = list()\n",
    "with open(os.path.join(save_dir, \"question.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        questions.append(data)\n",
    "\n",
    "# Example element\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metadata\n",
    "arena_hard_path = os.path.join(data_path, \"ArenaHard\")\n",
    "os.makedirs(arena_hard_path, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(arena_hard_path, \"metadata.json\")\n",
    "metadata = list()\n",
    "for question in questions:\n",
    "    metadata.append({\n",
    "        \"instruction\": question[\"prompt\"],\n",
    "        \"original_category\": question[\"category\"],\n",
    "        \"original_subcategory\": question[\"subcategory\"],\n",
    "        \"uid\": question[\"uid\"],\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "# Example element\n",
    "print(\"Example element:\")\n",
    "metadata[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dir = os.path.join(raw_path, \"arena-hard-auto\", \"data\", \"arena-hard-v2.0\", \"model_answer\")\n",
    "\n",
    "files = os.listdir(answers_dir)\n",
    "files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict = dict()\n",
    "\n",
    "for file in files:\n",
    "    model_name = file[:-6]\n",
    "    path = os.path.join(answers_dir, file)\n",
    "\n",
    "    answers = list()\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            answers.append(data)\n",
    "    \n",
    "    # show answers example\n",
    "    print(answers[0])\n",
    "    \n",
    "    answers_dict[model_name] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show answers example\n",
    "answers_dict[\"o3-mini-2025-01-31\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip with uid\n",
    "uid_to_question = dict()\n",
    "for item in metadata:\n",
    "    uid_to_question[item[\"uid\"]] = item[\"instruction\"]\n",
    "\n",
    "for file in files:\n",
    "    model_name = file[:-6]\n",
    "    answers = answers_dict[model_name]\n",
    "    print(model_name)\n",
    "    print(len(answers))\n",
    "    \n",
    "    new_dataset = list()\n",
    "    for answer in answers:\n",
    "        item = {\n",
    "            \"instruction\": uid_to_question[answer[\"uid\"]],\n",
    "            \"output\": answer['messages'][-1]['content']['answer']\n",
    "        }\n",
    "        new_dataset.append(item)\n",
    "    \n",
    "    print(\"Example Element:\")\n",
    "    print(new_dataset[0])\n",
    "        \n",
    "    save_path = os.path.join(arena_hard_path, f\"{model_name}.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(new_dataset, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subjective Dataset:\n",
    "1. yleo/emerton_dpo_pairs_judge\n",
    "2. Intel/orca_dpo_pairs\n",
    "3. jondurbin/py-dpo-v0.1\n",
    "4. jondurbin/truthy-dpo-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"yleo/emerton_dpo_pairs_judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"You will be given a definition of a task first, then some input of the task.\\nThis task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\\n\\nAFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\\nOutput:\",\n",
       " 'category': 'subjective'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emerton_dpo_path = os.path.join(data_path, \"EmertonDPO\")\n",
    "os.makedirs(emerton_dpo_path, exist_ok=True)\n",
    "save_path = os.path.join(emerton_dpo_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['train']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['input'],\n",
    "        \"category\": \"subjective\",\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'question', 'chosen', 'rejected'],\n",
       "        num_rows: 12859\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"Intel/orca_dpo_pairs\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"You will be given a definition of a task first, then some input of the task.\\nThis task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\\n\\nAFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\\nOutput:\",\n",
       " 'category': 'subjective'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca_dpo_path = os.path.join(data_path, \"OrcaDPO\")\n",
    "os.makedirs(orca_dpo_path, exist_ok=True)\n",
    "save_path = os.path.join(orca_dpo_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['train']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['question'],\n",
    "        \"category\": \"subjective\",\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46c43c0fb504e42a1ef8619879fbb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1125596966ba414695ed6612eba20bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "py-dpo.parquet:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1297c749384186a17bc1b484d2f2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected', 'id'],\n",
       "        num_rows: 9466\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"jondurbin/py-dpo-v0.1\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Use the function to debug the given program and prevent the segmentation fault. Your solution should also handle the case where the array contains duplicate elements. You are not allowed to use any additional data structures. Additionally, the time complexity of your solution should be O(n) and the space complexity should be O(1).\\n\\n```python\\ndef debug_program(arr):\\n    n = len(arr)\\n    for i in range(n):\\n        if arr[i] == i:\\n            return i\\n    return -1\\n\\n# Test Case\\narr = [0, 1, 2, 3, 4]\\nprint(debug_program(arr))  # Expected output: -1\\n```\\n\\n**Additional Requirements:**\\n\\n- The program should be able to handle arrays of any length.\\n- The program should be able to handle arrays with duplicate elements.\\n- The solution should use a divide and conquer approach to solve the problem.\\n- The solution should not modify the input array.\\n- The solution should be implemented in Python.',\n",
       " 'category': 'subjective',\n",
       " 'id': '8c94f83f-6a5a-5f8c-98a2-e242d7764938'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_dpo_path = os.path.join(data_path, \"PyDPO\")\n",
    "os.makedirs(py_dpo_path, exist_ok=True)\n",
    "save_path = os.path.join(py_dpo_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['train']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['prompt'],\n",
    "        \"category\": \"subjective\",\n",
    "        \"id\": item['id'],\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db497b93f4f243268ca0673754b74165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/904 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d498ca655c84e68b0a1ae69b60acbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "truthy-dpo.parquet:   0%|          | 0.00/653k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d6585d14884d8699a8d5e827efad04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'system', 'prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 1016\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"jondurbin/truthy-dpo-v0.1\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What's the nearest national park to you?\",\n",
       " 'category': 'subjective',\n",
       " 'id': '04c275bf738fd391b7fe25e25fe7bed3'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truthy_dpo_path = os.path.join(data_path, \"TruthyDPO\")\n",
    "os.makedirs(truthy_dpo_path, exist_ok=True)\n",
    "save_path = os.path.join(truthy_dpo_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['train']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['prompt'],\n",
    "        \"category\": \"subjective\",\n",
    "        \"id\": item['id'],\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Dataset: MMLU Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['question_id', 'question', 'options', 'answer', 'answer_index', 'cot_content', 'category', 'src'],\n",
       "        num_rows: 12032\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_id', 'question', 'options', 'answer', 'answer_index', 'cot_content', 'category', 'src'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"TIGER-Lab/MMLU-Pro\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'The symmetric group $S_n$ has $\\n\\\\factorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements.\\nFind the characteristic of the ring 2Z.',\n",
       " 'answer': 'A',\n",
       " 'category': 'math'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_pro_validation_path = os.path.join(data_path, \"MMLUPro\", \"validation\")\n",
    "os.makedirs(mmlu_pro_validation_path, exist_ok=True)\n",
    "save_path = os.path.join(mmlu_pro_validation_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['validation']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['question'],\n",
    "        \"answer\": item['answer'],\n",
    "        \"category\": item['category'],\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Typical advertising regulatory bodies suggest, for example that adverts must not: encourage _________, cause unnecessary ________ or _____, and must not cause _______ offence.',\n",
       " 'answer': 'I',\n",
       " 'category': 'business'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_pro_test_path = os.path.join(data_path, \"MMLUPro\", \"test\")\n",
    "os.makedirs(mmlu_pro_test_path, exist_ok=True)\n",
    "save_path = os.path.join(mmlu_pro_test_path, \"metadata.json\")\n",
    "\n",
    "metadata = list()\n",
    "for item in ds['test']:\n",
    "    metadata.append({\n",
    "        \"instruction\": item['question'],\n",
    "        \"answer\": item['answer'],\n",
    "        \"category\": item['category'],\n",
    "    })\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "metadata[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
